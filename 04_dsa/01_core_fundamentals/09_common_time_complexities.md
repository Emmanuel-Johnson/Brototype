# Common Time Complexities (in Plain Words)

## O(1) â€” Constant Time

- **Time does NOT change with input size.**
- No matter if N = 10 or N = 1,000,000 â†’ same time.

**Example:**
```python
x = arr[0]
```
- ðŸ‘‰ Always 1 step  
- ðŸ‘‰ O(1)

> ðŸ§  *Best possible complexity*

---

## O(log N) â€” Logarithmic Time

- **Time increases very slowly as N increases.**
- Happens when input size is cut in half each step.

**Example:**  
*Binary Search*

Array size:  
16 â†’ 8 â†’ 4 â†’ 2 â†’ 1

- ðŸ‘‰ O(log N)

> ðŸ§  *Big data, small time*

---

## O(N) â€” Linear Time

- **Time grows directly with input size.**
- If input doubles, time doubles.

**Example:**
```python
for i in range(n):
    print(i)
```
- ðŸ‘‰ Runs N times  
- ðŸ‘‰ O(N)

> ðŸ§  *One loop*

---

## O(N log N) â€” Linearithmic Time

- **A loop (N) with a log operation inside.**
- Common in efficient sorting algorithms.

**Example:**  
*Merge Sort*  
*Quick Sort (average case)*

- ðŸ‘‰ O(N log N)

> ðŸ§  *Fast sorting complexity*

---

## O(NÂ²) â€” Quadratic Time

- **Time grows very fast.**
- Usually caused by nested loops.

**Example:**
```python
for i in range(n):
    for j in range(n):
        print(i, j)
```
- ðŸ‘‰ N Ã— N operations  
- ðŸ‘‰ O(NÂ²)

> ðŸ§  *Slow for large data*

---

## Easiest Way to Remember ðŸ”¥

| Complexity   | Think of         |
|--------------|------------------|
| O(1)         | Direct access    |
| O(log N)     | Divide by 2      |
| O(N)         | Single loop      |
| O(N log N)   | Efficient sorting|
| O(NÂ²)        | Nested loops     |

---

## Interview Ranking (Best â†’ Worst)

**O(1) â†’ O(log N) â†’ O(N) â†’ O(N log N) â†’ O(NÂ²)**

> Loops decide time complexity. Nested loops make it worse.